{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(text):\n",
    "    text = text.replace('``', \"'\")\n",
    "    text = text.replace('`', \"'\")\n",
    "    text = text.replace(\"''\", \"'\")\n",
    "    text = text.replace(\" '\", \"'\")\n",
    "    return text\n",
    "\n",
    "with open(\"./evidence.json\", \"r\") as f:\n",
    "    evidences = json.load(f)\n",
    "    \n",
    "for evidence_id, evidence_text in evidences.items():\n",
    "    evidences[evidence_id] = clean_transcript(evidence_text)\n",
    "    \n",
    "corpus = list(evidences.values())\n",
    "evidences = tuple(evidences.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L12-v2\", device=\"cuda:1\")\n",
    "corpus_embeddings =embedding_model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "\n",
    "def retrieve_evidence(\n",
    "    query, corpus, corpus_embeddings, embedding_model, evidence_items, top_k=50\n",
    "):\n",
    "    \"\"\"Retrieves the top_k most similar evidence items for a given query.\"\"\"\n",
    "    if not embedding_model or corpus_embeddings is None:\n",
    "        print(\"Embedding model or corpus embeddings not available.\")\n",
    "        return []\n",
    "\n",
    "    query = clean_transcript(query)\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_scores = cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "\n",
    "    # Get top_k scores and indices\n",
    "    actual_top_k = min(top_k, len(corpus))\n",
    "    scores, indices = torch.topk(similarity_scores, k=actual_top_k)\n",
    "\n",
    "    # Map indices back to evidence items\n",
    "    most_relevant_evidences = [\n",
    "        (evidence_items[idx.item()], scores[i].item()) for i, idx in enumerate(indices)\n",
    "    ]\n",
    "    return most_relevant_evidences  # Return list of ((id, text), score) tuples\n",
    "\n",
    "def rerank_evidence(\n",
    "    query,\n",
    "    retrieved_evidence,\n",
    "    reranker_model,\n",
    "):\n",
    "    \"\"\"Reranks retrieved evidence using a CrossEncoder model.\"\"\"\n",
    "    if not retrieved_evidence:\n",
    "        print(\"No evidence provided for reranking.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        query = clean_transcript(query)\n",
    "\n",
    "        # Prepare input for the reranker: [query, evidence_text] pairs\n",
    "        reranker_input = [\n",
    "            [query, evidence[0][1]] for evidence in retrieved_evidence\n",
    "        ]  # evidence is ((id, text), score)\n",
    "\n",
    "        # Predict scores\n",
    "        scores = reranker_model.predict(reranker_input, show_progress_bar=True)\n",
    "\n",
    "        # Combine original evidence items with new scores and sort\n",
    "        # evidence[0] is the original (id, text) tuple\n",
    "        reranked_results = sorted(\n",
    "            zip(scores, [item[0] for item in retrieved_evidence]), reverse=True\n",
    "        )\n",
    "\n",
    "        print(\"Reranking complete.\")\n",
    "        # Return list of (rerank_score, (id, text)) tuples\n",
    "        return reranked_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during reranking: {e}\")\n",
    "        return []  # Return empty list on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Query: [South Australia] has the most expensive electricity in the world. ---\n",
      "\n",
      "Top 50 Retrieved Evidence (before reranking):\n",
      "  Score (Cosine Sim): 0.8508 - evidence-67732: [citation needed] South Australia has the highest retail price for electricity in the country....\n",
      "  Score (Cosine Sim): 0.8203 - evidence-572512: \"South Australia has the highest power prices in the world\"....\n",
      "  Score (Cosine Sim): 0.6736 - evidence-780332: Industrialised countries such as Canada, the US, and Australia are among the highest per capita cons...\n",
      "  Score (Cosine Sim): 0.6598 - evidence-1061888: Australia has one of the fastest deployment rates of renewable energy worldwide....\n",
      "  Score (Cosine Sim): 0.6283 - evidence-48256: One of the most powerful power grids in the world supplies power to the state of Queensland, Austral...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabe36f424f341f480953b22c67cf3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking complete.\n",
      "\n",
      "Top 5 Reranked Evidence:\n",
      "  Rank 1 (Score: 6.7758) - evidence-572512: \"South Australia has the highest power prices in the world\".\n",
      "  Rank 2 (Score: 6.6325) - evidence-67732: [citation needed] South Australia has the highest retail price for electricity in the country.\n",
      "  Rank 3 (Score: 2.1835) - evidence-780332: Industrialised countries such as Canada, the US, and Australia are among the highest per capita consumers of electricity in the world, which is possible thanks to a widespread electrical distribution network.\n",
      "  Rank 4 (Score: 1.8560) - evidence-723533: According to a Sierra Club analysis, the US Kemper Project, which was due to be online in 2017, is the most expensive power plant ever built for the watts of electricity it will generate.\n",
      "  Rank 5 (Score: 0.1382) - evidence-48256: One of the most powerful power grids in the world supplies power to the state of Queensland, Australia.\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "--- Processing Query: when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod­uces 1.3 per cent of this 3 per cent, then no amount of emissions reductio­n here will have any effect on global climate. ---\n",
      "\n",
      "Top 50 Retrieved Evidence (before reranking):\n",
      "  Score (Cosine Sim): 0.7379 - evidence-559290: Australia’s total greenhouse gas emissions increased by 0.3% in the first six months of the Carbon T...\n",
      "  Score (Cosine Sim): 0.6966 - evidence-584052: Beyond 2012 if the growth rate were reduced to three percent yearly, carbon emissions in 2030 would ...\n",
      "  Score (Cosine Sim): 0.6914 - evidence-419267: On 17 July 2014, a report by the Australian National University estimated that the Australian scheme...\n",
      "  Score (Cosine Sim): 0.6838 - evidence-1170010: Unanimous agreement was found among the models that future climate change will reduce the efficiency...\n",
      "  Score (Cosine Sim): 0.6770 - evidence-949910: Australian per-capita emissions of carbon dioxide in 2007 were 18.8 tons of CO, compared to the EU a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e1b27d71b746dca3150c39d22b1dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking complete.\n",
      "\n",
      "Top 5 Reranked Evidence:\n",
      "  Rank 1 (Score: 3.8120) - evidence-609211: The report mentioned that this would require global net human-caused emissions of carbon dioxide (CO2) to fall by about 45% from 2010 levels by 2030, reaching \"net zero\" around 2050, through “rapid and far-reaching” transitions in land, energy, industry, buildings, transport, and cities.\n",
      "  Rank 2 (Score: 3.5089) - evidence-215052: In 2008, countries with a Kyoto cap made up less than one-third of annual global carbon dioxide emissions from fuel combustion.\n",
      "  Rank 3 (Score: 3.0580) - evidence-677627: SR15 also has modelling that shows that, for global warming to be limited to 1.5 °C, \"Global net human-caused emissions of carbon dioxide (CO2) would need to fall by about 45 percent from 2010 levels by 2030, reaching'net zero' around 2050.\n",
      "  Rank 4 (Score: 2.3935) - evidence-584052: Beyond 2012 if the growth rate were reduced to three percent yearly, carbon emissions in 2030 would be 28 MT, which is 70 percent of the UK's entire carbon emissions budget that year for all sectors of society.\n",
      "  Rank 5 (Score: 2.3898) - evidence-730469: The report says that for limiting warming to below 1.5C \"global net human-caused emissions of CO2 would need to fall by about 45% from 2010 levels by 2030, reaching \"net zero\" around 2050.\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Processing Query: This means that the world is now 1C warmer than it was in pre-industrial times ---\n",
      "\n",
      "Top 50 Retrieved Evidence (before reranking):\n",
      "  Score (Cosine Sim): 0.7158 - evidence-694262: The planet is now 0.8 °C warmer than in pre-industrial times....\n",
      "  Score (Cosine Sim): 0.6986 - evidence-403673: Global Warming of 1.5 °C....\n",
      "  Score (Cosine Sim): 0.6898 - evidence-698376: In 2007 the National Oceanic and Atmospheric Administration stated that the \"U.S. and global annual ...\n",
      "  Score (Cosine Sim): 0.6673 - evidence-246929: It is a major aspect of climate change, and has been demonstrated by the instrumental temperature re...\n",
      "  Score (Cosine Sim): 0.6595 - evidence-1084381: The first chapter describes the expected effects of climate change with one degree (°C) increase in ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df16d33a467f48a794d9cc797784a211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking complete.\n",
      "\n",
      "Top 5 Reranked Evidence:\n",
      "  Rank 1 (Score: 6.5404) - evidence-694262: The planet is now 0.8 °C warmer than in pre-industrial times.\n",
      "  Rank 2 (Score: 5.0996) - evidence-889933: Multiple independently produced instrumental datasets confirm that the 2009–2018 decade was 0.93 ± 0.07 °C warmer than the pre-industrial baseline (1850–1900).\n",
      "  Rank 3 (Score: 4.5197) - evidence-590642: Nevertheless, the gases which have been emitted so far are unlikely to cause global temperature to rise to 1.5°C alone, meaning a global temperature rise to 1.5°C above pre-industrial levels is avoidable, assuming net zero emissions are reached soon.\n",
      "  Rank 4 (Score: 4.1413) - evidence-246929: It is a major aspect of climate change, and has been demonstrated by the instrumental temperature record which shows global warming of around 1 °C since the pre-industrial period, although the bulk of this (0.9°C) has occurred since 1970.\n",
      "  Rank 5 (Score: 3.8136) - evidence-1017598: Global warming will likely rise to 1.5°C above pre-industrial levels between 2030 and 2052 if warming continues to increase at the current rate.\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"[South Australia] has the most expensive electricity in the world.\",\n",
    "    \"when 3 per cent of total annual global emissions of carbon dioxide are from humans and Australia prod\\u00aduces 1.3 per cent of this 3 per cent, then no amount of emissions reductio\\u00adn here will have any effect on global climate.\",\n",
    "    \"This means that the world is now 1C warmer than it was in pre-industrial times\",\n",
    "]\n",
    "\n",
    "reranker_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L12-v2')\n",
    "top_k = 50\n",
    "final_top_n = 5\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n--- Processing Query: {query} ---\")\n",
    "\n",
    "    # 4. Retrieve Evidence (Initial Retrieval)\n",
    "    retrieved = retrieve_evidence(\n",
    "        query,\n",
    "        corpus,\n",
    "        corpus_embeddings,\n",
    "        embedding_model,\n",
    "        evidences,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    if not retrieved:\n",
    "        print(\"No relevant evidence found during initial retrieval.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTop {len(retrieved)} Retrieved Evidence (before reranking):\")\n",
    "    for (evidence_id, evidence_text), score in retrieved[\n",
    "        :5\n",
    "    ]:  # Show top 5 retrieved\n",
    "        print(\n",
    "            f\"  Score (Cosine Sim): {score:.4f} - {evidence_id}: {evidence_text[:100]}...\"\n",
    "        )  # Truncate long text\n",
    "\n",
    "    # 5. Rerank Evidence\n",
    "    # Use CPU for reranker by default as it's often efficient enough\n",
    "    reranked_results = rerank_evidence(\n",
    "        query, retrieved, reranker_model\n",
    "    )  # List of (score, (id, text))\n",
    "    if not reranked_results:\n",
    "        print(\"Reranking failed.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTop {final_top_n} Reranked Evidence:\")\n",
    "    for i, (score, (evidence_id, evidence_text)) in enumerate(\n",
    "        reranked_results[:final_top_n]\n",
    "    ):\n",
    "        print(f\"  Rank {i+1} (Score: {score:.4f}) - {evidence_id}: {evidence_text}\")\n",
    "\n",
    "    print(\"-\" * (len(query) + 20))  # Separator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
